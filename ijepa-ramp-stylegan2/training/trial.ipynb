{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f80036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a0c15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipykernel in /home/abelde/.local/lib/python3.9/site-packages (6.29.5)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (6.4.2)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.9/site-packages (from ipykernel) (20.9)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (26.4.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: nest-asyncio in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (8.18.1)\n",
      "Requirement already satisfied: psutil in /home/abelde/.local/lib/python3.9/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: decorator in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: stack-data in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions in /home/abelde/.local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/abelde/.local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /home/abelde/.local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.6.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/abelde/.local/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.9/site-packages (from packaging->ipykernel) (2.4.7)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/abelde/.local/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/abelde/.local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/abelde/.local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/abelde/.local/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.15.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/abelde/.local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/abelde/.local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/abelde/.local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Installed kernelspec nlp_venv in /home/abelde/.local/share/jupyter/kernels/nlp_venv\n"
     ]
    }
   ],
   "source": [
    "!source /scratch/gilbreth/abelde/NLP_Research/venv/bin/activate\n",
    "!pip install ipykernel\n",
    "!python -m ipykernel install --user --name nlp_venv --display-name \"Python (nlp_venv)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44aaed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/abelde/.local/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: fsspec in /home/abelde/.local/lib/python3.9/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: networkx in /home/abelde/.local/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: jinja2 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/abelde/.local/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: filelock in /home/abelde/.local/lib/python3.9/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/abelde/.local/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/abelde/.local/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13dcb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72307b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1bc3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467aad6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5082cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb6166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_features,                # Number of input features.\n",
    "        out_features,               # Number of output features.\n",
    "        bias            = True,     # Apply additive bias before the activation function?\n",
    "        activation      = 'linear', # Activation function: 'relu', 'lrelu', etc.\n",
    "        lr_multiplier   = 1,        # Learning rate multiplier.\n",
    "        bias_init       = 0,        # Initial value for the additive bias.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.weight = torch.nn.Parameter(torch.randn([out_features, in_features]) / lr_multiplier)\n",
    "        self.bias = torch.nn.Parameter(torch.full([out_features], np.float32(bias_init))) if bias else None\n",
    "        self.weight_gain = lr_multiplier / np.sqrt(in_features)\n",
    "        self.bias_gain = lr_multiplier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3afb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        z_dim,                      # Input latent (Z) dimensionality, 0 = no latent.\n",
    "        c_dim,                      # Conditioning label (C) dimensionality, 0 = no label.\n",
    "        w_dim,                      # Intermediate latent (W) dimensionality.\n",
    "        num_ws,                     # Number of intermediate latents to output, None = do not broadcast.\n",
    "        num_layers      = 8,        # Number of mapping layers.\n",
    "        embed_features  = None,     # Label embedding dimensionality, None = same as w_dim.\n",
    "        layer_features  = None,     # Number of intermediate features in the mapping layers, None = same as w_dim.\n",
    "        activation      = 'lrelu',  # Activation function: 'relu', 'lrelu', etc.\n",
    "        lr_multiplier   = 0.01,     # Learning rate multiplier for the mapping layers.\n",
    "        w_avg_beta      = 0.995,    # Decay for tracking the moving average of W during training, None = do not track.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.c_dim = c_dim\n",
    "        self.w_dim = w_dim\n",
    "        self.num_ws = num_ws\n",
    "        self.num_layers = num_layers\n",
    "        self.w_avg_beta = w_avg_beta\n",
    "\n",
    "        if embed_features is None:\n",
    "            embed_features = w_dim\n",
    "        if c_dim == 0:\n",
    "            embed_features = 0\n",
    "        if layer_features is None:\n",
    "            layer_features = w_dim\n",
    "        features_list = [z_dim + embed_features] + [layer_features] * (num_layers - 1) + [w_dim]\n",
    "\n",
    "        if c_dim > 0:\n",
    "            self.embed = FullyConnectedLayer(c_dim, embed_features)\n",
    "        for idx in range(num_layers):\n",
    "            in_features = features_list[idx]\n",
    "            out_features = features_list[idx + 1]\n",
    "            layer = FullyConnectedLayer(in_features, out_features, activation=activation, lr_multiplier=lr_multiplier)\n",
    "            setattr(self, f'fc{idx}', layer)\n",
    "\n",
    "        # if num_ws is not None and w_avg_beta is not None:\n",
    "        #     self.register_buffer('w_avg', torch.zeros([w_dim]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b218de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisLayer(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_channels,                    # Number of input channels.\n",
    "        out_channels,                   # Number of output channels.\n",
    "        w_dim,                          # Intermediate latent (W) dimensionality.\n",
    "        resolution,                     # Resolution of this layer.\n",
    "        kernel_size     = 3,            # Convolution kernel size.\n",
    "        up              = 1,            # Integer upsampling factor.\n",
    "        use_noise       = True,         # Enable noise input?\n",
    "        activation      = 'lrelu',      # Activation function: 'relu', 'lrelu', etc.\n",
    "        resample_filter = [1,3,3,1],    # Low-pass filter to apply when resampling activations.\n",
    "        conv_clamp      = None,         # Clamp the output of convolution layers to +-X, None = disable clamping.\n",
    "        channels_last   = False,        # Use channels_last format for the weights?\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.resolution = resolution\n",
    "        self.up = up\n",
    "        self.use_noise = use_noise\n",
    "        self.activation = activation\n",
    "        self.conv_clamp = conv_clamp\n",
    "        # self.register_buffer('resample_filter', upfirdn2d.setup_filter(resample_filter))\n",
    "        self.padding = kernel_size // 2\n",
    "        # self.act_gain = bias_act.activation_funcs[activation].def_gain\n",
    "\n",
    "        self.affine = FullyConnectedLayer(w_dim, in_channels, bias_init=1)\n",
    "        memory_format = torch.channels_last if channels_last else torch.contiguous_format\n",
    "        self.weight = torch.nn.Parameter(torch.randn([out_channels, in_channels, kernel_size, kernel_size]).to(memory_format=memory_format))\n",
    "        if use_noise:\n",
    "            self.register_buffer('noise_const', torch.randn([resolution, resolution]))\n",
    "            self.noise_strength = torch.nn.Parameter(torch.zeros([]))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros([out_channels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab31cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToRGBLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, w_dim, kernel_size=1, conv_clamp=None, channels_last=False):\n",
    "        super().__init__()\n",
    "        self.conv_clamp = conv_clamp\n",
    "        self.affine = FullyConnectedLayer(w_dim, in_channels, bias_init=1)\n",
    "        memory_format = torch.channels_last if channels_last else torch.contiguous_format\n",
    "        self.weight = torch.nn.Parameter(torch.randn([out_channels, in_channels, kernel_size, kernel_size]).to(memory_format=memory_format))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros([out_channels]))\n",
    "        self.weight_gain = 1 / np.sqrt(in_channels * (kernel_size ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee0d385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisBlock(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_channels,                        # Number of input channels, 0 = first block.\n",
    "        out_channels,                       # Number of output channels.\n",
    "        w_dim,                              # Intermediate latent (W) dimensionality.\n",
    "        resolution,                         # Resolution of this block.\n",
    "        img_channels,                       # Number of output color channels.\n",
    "        is_last,                            # Is this the last block?\n",
    "        architecture        = 'skip',       # Architecture: 'orig', 'skip', 'resnet'.\n",
    "        resample_filter     = [1,3,3,1],    # Low-pass filter to apply when resampling activations.\n",
    "        conv_clamp          = None,         # Clamp the output of convolution layers to +-X, None = disable clamping.\n",
    "        use_fp16            = False,        # Use FP16 for this block?\n",
    "        fp16_channels_last  = False,        # Use channels-last memory format with FP16?\n",
    "        **layer_kwargs,                     # Arguments for SynthesisLayer.\n",
    "    ):\n",
    "        assert architecture in ['orig', 'skip', 'resnet']\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.w_dim = w_dim\n",
    "        self.resolution = resolution\n",
    "        self.img_channels = img_channels\n",
    "        self.is_last = is_last\n",
    "        self.architecture = architecture\n",
    "        self.use_fp16 = use_fp16\n",
    "        self.channels_last = (use_fp16 and fp16_channels_last)\n",
    "        # self.register_buffer('resample_filter', upfirdn2d.setup_filter(resample_filter))\n",
    "        self.num_conv = 0\n",
    "        self.num_torgb = 0\n",
    "\n",
    "        if in_channels == 0:\n",
    "            self.const = torch.nn.Parameter(torch.randn([out_channels, resolution, resolution]))\n",
    "\n",
    "        if in_channels != 0:\n",
    "            self.conv0 = SynthesisLayer(in_channels, out_channels, w_dim=w_dim, resolution=resolution, up=2,\n",
    "                resample_filter=resample_filter, conv_clamp=conv_clamp, channels_last=self.channels_last, **layer_kwargs)\n",
    "            self.num_conv += 1\n",
    "\n",
    "        self.conv1 = SynthesisLayer(out_channels, out_channels, w_dim=w_dim, resolution=resolution,\n",
    "            conv_clamp=conv_clamp, channels_last=self.channels_last, **layer_kwargs)\n",
    "        self.num_conv += 1\n",
    "\n",
    "        if is_last or architecture == 'skip':\n",
    "            self.torgb = ToRGBLayer(out_channels, img_channels, w_dim=w_dim,\n",
    "                conv_clamp=conv_clamp, channels_last=self.channels_last)\n",
    "            self.num_torgb += 1\n",
    "\n",
    "        if in_channels != 0 and architecture == 'resnet':\n",
    "            self.skip = Conv2dLayer(in_channels, out_channels, kernel_size=1, bias=False, up=2,\n",
    "                resample_filter=resample_filter, channels_last=self.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8892ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        w_dim,                      # Intermediate latent (W) dimensionality.\n",
    "        img_resolution,             # Output image resolution.\n",
    "        img_channels,               # Number of color channels.\n",
    "        channel_base    = 32768,    # Overall multiplier for the number of channels.\n",
    "        channel_max     = 512,      # Maximum number of channels in any layer.\n",
    "        num_fp16_res    = 0,        # Use FP16 for the N highest resolutions.\n",
    "        **block_kwargs,             # Arguments for SynthesisBlock.\n",
    "    ):\n",
    "        assert img_resolution >= 4 and img_resolution & (img_resolution - 1) == 0\n",
    "        super().__init__()\n",
    "        self.w_dim = w_dim\n",
    "        self.img_resolution = img_resolution\n",
    "        self.img_resolution_log2 = int(np.log2(img_resolution))\n",
    "        self.img_channels = img_channels\n",
    "        self.block_resolutions = [2 ** i for i in range(2, self.img_resolution_log2 + 1)]\n",
    "        channels_dict = {res: min(channel_base // res, channel_max) for res in self.block_resolutions}\n",
    "        fp16_resolution = max(2 ** (self.img_resolution_log2 + 1 - num_fp16_res), 8)\n",
    "\n",
    "        self.num_ws = 0\n",
    "        for res in self.block_resolutions:\n",
    "            in_channels = channels_dict[res // 2] if res > 4 else 0\n",
    "            print(\"in_channels\",in_channels)\n",
    "            out_channels = channels_dict[res]\n",
    "            print(\"out_channels\", out_channels)\n",
    "            use_fp16 = (res >= fp16_resolution)\n",
    "            print(use_fp16)\n",
    "            is_last = (res == self.img_resolution)\n",
    "            print(is_last)\n",
    "            block = SynthesisBlock(in_channels, out_channels, w_dim=w_dim, resolution=res,\n",
    "                img_channels=img_channels, is_last=is_last, use_fp16=use_fp16, **block_kwargs)\n",
    "            self.num_ws += block.num_conv\n",
    "            if is_last:\n",
    "                self.num_ws += block.num_torgb\n",
    "            setattr(self, f'b{res}', block)\n",
    "        print(self.num_ws)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d1f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        z_dim,                      # Input latent (Z) dimensionality.\n",
    "        c_dim,                      # Conditioning label (C) dimensionality.\n",
    "        w_dim,                      # Intermediate latent (W) dimensionality.\n",
    "        img_resolution,             # Output resolution.\n",
    "        img_channels,               # Number of output color channels.\n",
    "        mapping_kwargs      = {},   # Arguments for MappingNetwork.\n",
    "        synthesis_kwargs    = {},   # Arguments for SynthesisNetwork.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.c_dim = c_dim\n",
    "        self.w_dim = w_dim\n",
    "        self.img_resolution = img_resolution\n",
    "        self.img_channels = img_channels\n",
    "        self.synthesis = SynthesisNetwork(w_dim=w_dim, img_resolution=img_resolution, img_channels=img_channels, **synthesis_kwargs)\n",
    "        self.num_ws = self.synthesis.num_ws\n",
    "        self.mapping = MappingNetwork(z_dim=z_dim, c_dim=c_dim, w_dim=w_dim, num_ws=self.num_ws, **mapping_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf09721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "971e2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels 0\n",
      "out_channels 512\n",
      "False\n",
      "False\n",
      "in_channels 512\n",
      "out_channels 512\n",
      "False\n",
      "False\n",
      "in_channels 512\n",
      "out_channels 512\n",
      "False\n",
      "False\n",
      "in_channels 512\n",
      "out_channels 512\n",
      "False\n",
      "False\n",
      "in_channels 512\n",
      "out_channels 512\n",
      "False\n",
      "False\n",
      "in_channels 512\n",
      "out_channels 256\n",
      "False\n",
      "False\n",
      "in_channels 256\n",
      "out_channels 128\n",
      "False\n",
      "False\n",
      "in_channels 128\n",
      "out_channels 64\n",
      "False\n",
      "True\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "synthesis = SynthesisNetwork(512, 512, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "969d3464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 16, 32, 64, 128, 256, 512]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesis.block_resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "097ddc77",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SynthesisNetwork' object has no attribute 'channels_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msynthesis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels_dict\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SynthesisNetwork' object has no attribute 'channels_dict'"
     ]
    }
   ],
   "source": [
    "synthesis.channels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47272e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'synthesis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msynthesis\u001b[49m\u001b[38;5;241m.\u001b[39mfp16_resolution\n",
      "\u001b[0;31mNameError\u001b[0m: name 'synthesis' is not defined"
     ]
    }
   ],
   "source": [
    "synthesis.fp16_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b19e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Anaconda 2021.05)",
   "language": "python",
   "name": "anaconda-2021.05-py38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
